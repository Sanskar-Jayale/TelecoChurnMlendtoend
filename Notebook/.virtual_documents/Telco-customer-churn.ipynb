pip install catboost





import os
os.environ["LOKY_MAX_CPU_COUNT"] = "4"  # or the number of cores you want



import pandas as pd
import numpy as np
import json
import os


df = pd.read_csv(r"D:\Sanskar\TelecoChurnMlendtoend\Dataset\Telco-Customer-Churn.csv")
df.head()


#Drop CustomerID Feature(column)
df = df.drop('customerID',axis=1)
df.head()


df.info()


df.describe(include='all')


# totalCharges = df.columns.get_loc('TotalCharges')
# new_col = pd.to_numeric(df.iloc[:, totalCharges],errors = 'coerce')
# df.iloc[:, totalCharges] = pd.Series(new_col)
df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")


print(df['TotalCharges'].dtype)


df.describe(include='all')


# Handle any NaN values
print(df.isnull().values.any())
df.isnull().sum()


df[df["TotalCharges"].isna()][["tenure", "MonthlyCharges", "TotalCharges"]]



df = df.dropna(subset = ["TotalCharges"])


print(df.isnull().values.any())
df.isnull().sum()


columns_idx = np.s_[0:] # Slice of first row(header) with all columns.
first_record_idx = np.s_[0] # Index of first record

string_fields = [type(fld) is str for fld in df.iloc[first_record_idx, columns_idx]] # All string fields
all_features = [x for x in df.columns if x != 'Churn']
categorical_columns = list(np.array(df.columns)[columns_idx][string_fields])
categorical_features = [x for x in categorical_columns if x != 'Churn']
continuous_features = [x for x in all_features if x not in categorical_features]


import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder


sns.set(style='darkgrid')
sns.set_palette('hls',3)


print(df.groupby(['Churn']).size())
churn_plot = sns.countplot(data=df, x='Churn', order=df.Churn.value_counts().index)
plt.ylabel('Count')
for p in churn_plot.patches:
    height = p.get_height()
    churn_plot.text(p.get_x()+p.get_width()/2., height + 1,'{0:.0%}'.format(height/float(len(df))),ha="center") 
plt.show()


# Categorical feature count plots
f, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9), (ax10, ax11, ax12), (ax13, ax14, ax15)) = plt.subplots(5, 3, figsize=(20, 20))
ax = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9, ax10, ax11, ax12, ax13, ax14, ax15 ]

for i in range(len(categorical_features)):
    sns.countplot(x = categorical_features[i], hue="Churn", data=df, ax=ax[i])


fig, ax = plt.subplots(2, 2, figsize=(28, 8))
df[df.Churn == 'No'][continuous_features].hist(bins=20, color="blue", alpha=0.5, ax=ax)
df[df.Churn == 'Yes'][continuous_features].hist(bins=20, color="orange", alpha=0.5, ax=ax)


gr = sns.PairGrid(df, height=5, hue="Churn")
gr = gr.map_diag(plt.hist)
gr = gr.map_offdiag(plt.scatter)
gr = gr.add_legend()


f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(25, 25))
ax = [ax1, ax2, ax3, ax4]

for i in range(len(continuous_features)):
    sns.boxplot(x = 'Churn', y = continuous_features[i], data=df, ax=ax[i])


import pandas as pd

# target
y = df["Churn"]

# features
X = df.drop(columns=["Churn"])



categorical_cols = X.select_dtypes(include=['object']).columns
numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns

categorical_cols, numeric_cols



from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, accuracy_score, classification_report
import joblib

# target
y = df["Churn"]

# features
X = df.drop(columns=["Churn"])

# your detected column groups
categorical_cols = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',
        'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
        'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',
        'PaperlessBilling', 'PaymentMethod']

numeric_cols = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']

# preprocessing
preprocess = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),
        ('num', 'passthrough', numeric_cols)
    ]
)

# train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Random Forest model
clf = Pipeline(steps=[
    ('preprocess', preprocess),
    ('model', RandomForestClassifier(
        n_estimators=200,
        random_state=42,
        class_weight="balanced",   # handles imbalance in churn dataset
    ))
])

# train
clf.fit(X_train, y_train)

# predictions
y_pred = clf.predict(X_test)
y_prob = clf.predict_proba(X_test)[:, 1]

# evaluation
print("Accuracy:", accuracy_score(y_test, y_pred))
print("ROC-AUC:", roc_auc_score(y_test, y_prob))
print(classification_report(y_test, y_pred))

# save model
joblib.dump(clf, "churn_random_forest.pkl")
print("Model saved as churn_random_forest.pkl")



from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

# Define categorical and numeric columns
cat_cols = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',
            'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
            'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',
            'PaperlessBilling', 'PaymentMethod']
num_cols = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']

# Preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),
        ('num', 'passthrough', num_cols)
    ]
)

# Random Forest with class weights
rf = RandomForestClassifier(
    n_estimators=200,
    max_depth=8,
    min_samples_leaf=4,
    max_features='sqrt',
    class_weight={'No':1, 'Yes':3},  # increase weight for churn
    random_state=42
)

# Full pipeline
rf_pipeline = Pipeline([
    ('preprocess', preprocessor),
    ('rf', rf)
])

# Fit the model
rf_pipeline.fit(X_train, y_train)  # y_train is still 'No'/'Yes'



from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

y_pred = rf_pipeline.predict(X_test)
y_prob = rf_pipeline.predict_proba(X_test)[:, 1]

print("Accuracy:", accuracy_score(y_test, y_pred))
print("ROC-AUC:", roc_auc_score(y_test.map({'No':0,'Yes':1}), y_prob))
print(classification_report(y_test, y_pred))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['No','Yes'], yticklabels=['No','Yes'])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()



from imblearn.over_sampling import SMOTE

# OneHotEncode categorical features first
X_train_encoded = preprocessor.fit_transform(X_train)
X_test_encoded = preprocessor.transform(X_test)

# Apply SMOTE
sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X_train_encoded, y_train.map({'No':0,'Yes':1}))

# Train Random Forest on balanced data
rf_smote = RandomForestClassifier(
    n_estimators=200,
    max_depth=8,
    min_samples_leaf=4,
    max_features='sqrt',
    random_state=42
)
rf_smote.fit(X_res, y_res)

# Predict
y_pred = rf_smote.predict(X_test_encoded)
y_prob = rf_smote.predict_proba(X_test_encoded)[:,1]

from sklearn.metrics import classification_report, accuracy_score, roc_auc_score
print("Accuracy:", accuracy_score(y_test.map({'No':0,'Yes':1}), y_pred))
print("ROC-AUC:", roc_auc_score(y_test.map({'No':0,'Yes':1}), y_prob))
print(classification_report(y_test.map({'No':0,'Yes':1}), y_pred))



# Models
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from catboost import CatBoostClassifier

# Preprocessing & pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Metrics
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix

# Imbalance handling
from imblearn.over_sampling import SMOTE

# Utilities
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt



cat_cols = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',
            'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
            'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',
            'PaperlessBilling', 'PaymentMethod']
num_cols = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']

# Encode target
y_train_num = y_train.map({'No':0, 'Yes':1})
y_test_num = y_test.map({'No':0, 'Yes':1})



# OneHotEncode categorical features
preprocessor_rf = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),
        ('num', 'passthrough', num_cols)
    ]
)

# SMOTE on encoded training data
X_train_encoded = preprocessor_rf.fit_transform(X_train)
X_test_encoded = preprocessor_rf.transform(X_test)

sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X_train_encoded, y_train_num)

rf = RandomForestClassifier(
    n_estimators=200,
    max_depth=8,
    min_samples_leaf=4,
    max_features='sqrt',
    random_state=42
)
rf.fit(X_res, y_res)



xgb = XGBClassifier(
    n_estimators=500,
    max_depth=6,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    eval_metric='logloss',
    scale_pos_weight=len(y_train_num[y_train_num==0])/len(y_train_num[y_train_num==1]),
    random_state=42
)
xgb.fit(X_res, y_res)



# CatBoost accepts categorical columns as indices
cat_features_indices = [X_train.columns.get_loc(c) for c in cat_cols]

catboost = CatBoostClassifier(
    iterations=500,
    depth=6,
    learning_rate=0.05,
    eval_metric='F1',
    random_seed=42,
    verbose=0,
    class_weights=[1, len(y_train_num[y_train_num==0])/len(y_train_num[y_train_num==1])]
)
catboost.fit(X_train, y_train_num, cat_features=cat_features_indices)



from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score

models = {'RandomForest': rf, 'XGBoost': xgb, 'CatBoost': catboost}
results = {}

# Determine the positive class: 1 or 'Yes'
pos_class = 1  # If using numeric labels; set to 'Yes' if using strings

for name, model in models.items():
    # Predict
    if name == 'CatBoost':
        y_pred = model.predict(X_test)
        y_pred = y_pred.astype(int)  # convert float to int
        y_prob = model.predict_proba(X_test)[:,1]
    else:
        y_pred = model.predict(X_test_encoded)
        y_prob = model.predict_proba(X_test_encoded)[:,1]

    # Metrics
    acc = accuracy_score(y_test_num, y_pred)
    roc = roc_auc_score(y_test_num, y_prob)
    f1 = f1_score(y_test_num, y_pred, pos_label=pos_class)
    recall = recall_score(y_test_num, y_pred, pos_label=pos_class)

    results[name] = {
        'accuracy': acc,
        'roc_auc': roc,
        'f1_yes': f1,
        'recall_yes': recall
    }

# Compare results
results_df = pd.DataFrame(results).T
print(results_df)

# Optional: Bar plot
results_df[['accuracy','roc_auc','f1_yes','recall_yes']].plot(kind='bar', figsize=(10,6))
plt.title("Model Comparison")
plt.ylabel("Score")
plt.show()



import joblib
joblib.dump(catboost, "catboost_churn_model.pkl")



import matplotlib.pyplot as plt
import seaborn as sns

feat_imp = pd.Series(catboost.get_feature_importance(), index=X_train.columns)
feat_imp.sort_values(ascending=False).plot(kind='bar', figsize=(12,6))
plt.title("CatBoost Feature Importance")
plt.show()

